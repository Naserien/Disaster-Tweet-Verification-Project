{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-22T21:04:56.665958Z","iopub.execute_input":"2023-12-22T21:04:56.666372Z","iopub.status.idle":"2023-12-22T21:04:56.673954Z","shell.execute_reply.started":"2023-12-22T21:04:56.666343Z","shell.execute_reply":"2023-12-22T21:04:56.673054Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#import the library\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.nn import BatchNorm1d\nfrom torch.nn.utils import clip_grad_norm_\nfrom torch.optim.lr_scheduler import StepLR\nimport numpy as np\nimport torch\nfrom sklearn.metrics import f1_score\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:56.675861Z","iopub.execute_input":"2023-12-22T21:04:56.676232Z","iopub.status.idle":"2023-12-22T21:04:56.682985Z","shell.execute_reply.started":"2023-12-22T21:04:56.676198Z","shell.execute_reply":"2023-12-22T21:04:56.682009Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"#imoort the dataset\ntraining_dataset = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntesting_dataset = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:56.684112Z","iopub.execute_input":"2023-12-22T21:04:56.684443Z","iopub.status.idle":"2023-12-22T21:04:56.721065Z","shell.execute_reply.started":"2023-12-22T21:04:56.684412Z","shell.execute_reply":"2023-12-22T21:04:56.720296Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"#check the dataset\ntraining_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:56.722851Z","iopub.execute_input":"2023-12-22T21:04:56.723124Z","iopub.status.idle":"2023-12-22T21:04:56.733416Z","shell.execute_reply.started":"2023-12-22T21:04:56.723100Z","shell.execute_reply":"2023-12-22T21:04:56.732475Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Read the dataset, acknowledge what each column means.\ntarget:If it's about the real disaster, it's a 1. If not, it's a 0.","metadata":{}},{"cell_type":"code","source":"testing_dataset.head()\n#It doesn't have the target, which we need to predict.","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:56.734581Z","iopub.execute_input":"2023-12-22T21:04:56.734871Z","iopub.status.idle":"2023-12-22T21:04:56.747362Z","shell.execute_reply.started":"2023-12-22T21:04:56.734846Z","shell.execute_reply":"2023-12-22T21:04:56.746441Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Use the train_test_split to split the data\n#test_size = 0.2,We make 20% of the dataset to be the validation dataset\ntrn_data,val_data,trn_labels,val_labels = train_test_split(training_dataset['text'],training_dataset['target'],test_size = 0.2,random_state=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:56.748444Z","iopub.execute_input":"2023-12-22T21:04:56.748738Z","iopub.status.idle":"2023-12-22T21:04:56.760086Z","shell.execute_reply.started":"2023-12-22T21:04:56.748714Z","shell.execute_reply":"2023-12-22T21:04:56.759383Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"#Now we get the text data\ntrn_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:56.761140Z","iopub.execute_input":"2023-12-22T21:04:56.761428Z","iopub.status.idle":"2023-12-22T21:04:56.772687Z","shell.execute_reply.started":"2023-12-22T21:04:56.761403Z","shell.execute_reply":"2023-12-22T21:04:56.771890Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"2572    @MsMigot wow what convincing &amp; compelling ...\n1813    http://t.co/iGXRqPoTm7 Bin Laden family plane ...\n2767    70 Years After Atomic Bombs Japan Still Strugg...\n6248    @PyrBliss ah I remember those days. In a snows...\n7563                            I wrecked my stomach help\nName: text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\n\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:56.773734Z","iopub.execute_input":"2023-12-22T21:04:56.773992Z","iopub.status.idle":"2023-12-22T21:04:57.737251Z","shell.execute_reply.started":"2023-12-22T21:04:56.773970Z","shell.execute_reply":"2023-12-22T21:04:57.736491Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_text(text, tokenizer, max_length):\n    #将文本转换成BERT可以理解的格式\n    encoding = tokenizer.encode_plus(\n        text,\n        #处理后文本的最大长度。如果文本超过这个长度，它会被截断。\n        max_length=max_length,\n        #如果文本超过max_length，这个选项会使文本被截断。\n        truncation=True,\n        #如果文本短于max_length，这个选项将以填充的方式扩展文本长度至max_length。\n        padding='max_length',\n        #return_tensors='pt': 指定返回的数据类型为PyTorch张量（tensor）。\n        return_tensors='pt'\n    )\n    \n    return {\n        'input_ids': encoding['input_ids'].squeeze(),\n        'attention_mask': encoding['attention_mask'].squeeze()\n    }","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:57.740348Z","iopub.execute_input":"2023-12-22T21:04:57.740635Z","iopub.status.idle":"2023-12-22T21:04:57.746206Z","shell.execute_reply.started":"2023-12-22T21:04:57.740611Z","shell.execute_reply":"2023-12-22T21:04:57.745346Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"max_length = 64\ntrain_encodings = trn_data.apply(lambda x: preprocess_text(x, tokenizer, max_length))\nval_encodings = val_data.apply(lambda x: preprocess_text(x, tokenizer, max_length))\ntest_encodings = testing_dataset['text'].apply(lambda x: preprocess_text(x, tokenizer, max_length))","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:04:57.747313Z","iopub.execute_input":"2023-12-22T21:04:57.747668Z","iopub.status.idle":"2023-12-22T21:05:08.099611Z","shell.execute_reply.started":"2023-12-22T21:04:57.747636Z","shell.execute_reply":"2023-12-22T21:05:08.098753Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"train_input_ids = torch.stack([enc['input_ids'] for enc in train_encodings])\ntrain_attention_mask = torch.stack([enc['attention_mask'] for enc in train_encodings])\ntrain_labels = torch.tensor(trn_labels.values)\n\nval_input_ids = torch.stack([enc['input_ids'] for enc in val_encodings])\nval_attention_mask = torch.stack([enc['attention_mask'] for enc in val_encodings])\nval_labels = torch.tensor(val_labels.values)\n\ntest_input_ids = torch.stack([enc['input_ids'] for enc in test_encodings])\ntest_attention_mask = torch.stack([enc['attention_mask'] for enc in test_encodings])","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:05:08.103253Z","iopub.execute_input":"2023-12-22T21:05:08.103572Z","iopub.status.idle":"2023-12-22T21:05:08.145249Z","shell.execute_reply.started":"2023-12-22T21:05:08.103544Z","shell.execute_reply":"2023-12-22T21:05:08.144343Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels)\nval_dataset = TensorDataset(val_input_ids, val_attention_mask, val_labels)\ntest_dataset = TensorDataset(test_input_ids, test_attention_mask)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:05:08.146396Z","iopub.execute_input":"2023-12-22T21:05:08.146711Z","iopub.status.idle":"2023-12-22T21:05:08.151269Z","shell.execute_reply.started":"2023-12-22T21:05:08.146686Z","shell.execute_reply":"2023-12-22T21:05:08.150340Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW([\n    {'params': model.bert.parameters(), 'lr': 1e-5},  # Adjusted for BERT's main parameters\n    {'params': model.classifier.parameters(), 'lr': 1e-3}  # Classifier remains the same\n], lr=5e-6)\ncriterion = torch.nn.CrossEntropyLoss()\nscheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:05:08.152445Z","iopub.execute_input":"2023-12-22T21:05:08.152790Z","iopub.status.idle":"2023-12-22T21:05:08.169878Z","shell.execute_reply.started":"2023-12-22T21:05:08.152766Z","shell.execute_reply":"2023-12-22T21:05:08.168975Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:05:08.171487Z","iopub.execute_input":"2023-12-22T21:05:08.171785Z","iopub.status.idle":"2023-12-22T21:05:08.177114Z","shell.execute_reply.started":"2023-12-22T21:05:08.171761Z","shell.execute_reply":"2023-12-22T21:05:08.176314Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:05:08.178150Z","iopub.execute_input":"2023-12-22T21:05:08.178388Z","iopub.status.idle":"2023-12-22T21:05:08.517688Z","shell.execute_reply.started":"2023-12-22T21:05:08.178367Z","shell.execute_reply":"2023-12-22T21:05:08.516825Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n      (position_embeddings): Embedding(512, 1024)\n      (token_type_embeddings): Embedding(2, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:05:08.518894Z","iopub.execute_input":"2023-12-22T21:05:08.519255Z","iopub.status.idle":"2023-12-22T21:05:08.597007Z","shell.execute_reply.started":"2023-12-22T21:05:08.519222Z","shell.execute_reply":"2023-12-22T21:05:08.595964Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    for batch in train_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n\n        # 梯度裁剪\n        clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        optimizer.step()\n\n    # 学习率调度程序更新\n    scheduler.step()\n\n    model.eval()\n    val_loss = 0.0\n    correct_preds = 0\n    all_preds = []  # 初始化列表以收集所有预测\n    all_labels = []  # 初始化列表以收集所有标签\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids, attention_mask, labels = batch\n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            val_loss += loss.item()\n\n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=1)\n            correct_preds += torch.sum(preds == labels).item()\n            all_preds.extend(preds.cpu().numpy())  # 收集预测\n            all_labels.extend(labels.cpu().numpy())  # 收集标签\n\n    val_accuracy = correct_preds / len(val_data)\n    f1 = f1_score(all_labels, all_preds, average='macro')  # 计算F1分数\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, F1 Score: {f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:05:08.598361Z","iopub.execute_input":"2023-12-22T21:05:08.598680Z","iopub.status.idle":"2023-12-22T21:17:25.366283Z","shell.execute_reply.started":"2023-12-22T21:05:08.598655Z","shell.execute_reply":"2023-12-22T21:17:25.365371Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"Epoch 1/5, Validation Loss: 37.7519, Validation Accuracy: 0.8398, F1 Score: 0.8330\nEpoch 2/5, Validation Loss: 44.0355, Validation Accuracy: 0.8418, F1 Score: 0.8370\nEpoch 3/5, Validation Loss: 42.9483, Validation Accuracy: 0.8391, F1 Score: 0.8348\nEpoch 4/5, Validation Loss: 42.8975, Validation Accuracy: 0.8398, F1 Score: 0.8354\nEpoch 5/5, Validation Loss: 42.8781, Validation Accuracy: 0.8398, F1 Score: 0.8354\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids, attention_mask = batch  # 不再需要 labels\n        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        preds = torch.argmax(logits, dim=1)\n        predictions.extend(preds.cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:17:25.367638Z","iopub.execute_input":"2023-12-22T21:17:25.367967Z","iopub.status.idle":"2023-12-22T21:17:46.271241Z","shell.execute_reply.started":"2023-12-22T21:17:25.367935Z","shell.execute_reply":"2023-12-22T21:17:46.270455Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({'id': testing_dataset['id'], 'target': predictions})\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T21:17:46.272316Z","iopub.execute_input":"2023-12-22T21:17:46.272613Z","iopub.status.idle":"2023-12-22T21:17:46.301299Z","shell.execute_reply.started":"2023-12-22T21:17:46.272586Z","shell.execute_reply":"2023-12-22T21:17:46.300444Z"},"trusted":true},"execution_count":102,"outputs":[]}]}